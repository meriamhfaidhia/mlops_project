import argparse
import logging

from model_pipeline import (
    prepare_data,
    train_model,
    evaluate_model,
    save_model,
    load_model
)


def main():
    """
    Pipeline de Machine Learning :
    - Pr√©traitement des donn√©es
    - Entra√Ænement du mod√®le
    - √âvaluation
    - Sauvegarde/Chargement
    - Pr√©diction
    - Affichage des versions enregistr√©es dans MLflow
    """
    # Configurer le logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s"
    )

    # Parser des arguments
    parser = argparse.ArgumentParser(
        description="Pipeline de Machine Learning pour la pr√©diction du churn."
    )

    # Arguments du script
    parser.add_argument(
        "--prepare", action="store_true", help="Pr√©parer les donn√©es."
    )
    parser.add_argument(
        "--train", action="store_true", help="Entra√Æner le mod√®le."
    )
    parser.add_argument(
        "--evaluate", action="store_true", help="√âvaluer le mod√®le."
    )
    parser.add_argument(
        "--save", type=str, help="Sauvegarder le mod√®le dans un fichier."
    )
    parser.add_argument(
        "--load", type=str, help="Charger un mod√®le existant."
    )
    parser.add_argument(
        "--train_path", type=str, required=True,
        help="Chemin du fichier CSV d'entra√Ænement."
    )
    parser.add_argument(
        "--test_path", type=str, required=True,
        help="Chemin du fichier CSV de test."
    )

    # Analyser les arguments
    args = parser.parse_args()

    # Pr√©paration des donn√©es
    logging.info("üîÑ Chargement et pr√©paration des donn√©es...")
    X_train, X_test, y_train, y_test = prepare_data(
        args.train_path, args.test_path
    )

    model = None

    # Si un mod√®le doit √™tre charg√©
    if args.load:
        logging.info(f"üì• Chargement du mod√®le depuis {args.load}...")
        model = load_model(args.load)

    # Si le mod√®le doit √™tre entra√Æn√©
    if args.train:
        logging.info("üöÄ Entra√Ænement du mod√®le...")
        model, params = train_model(X_train, y_train)

        if model:
            logging.info("‚úÖ Mod√®le entra√Æn√© avec succ√®s. Param√®tres :")
            for param, value in params.items():
                logging.info(f"{param}: {value}")

    # Si un mod√®le est disponible, √©valuation des performances
    if model and args.evaluate:
        logging.info("üìä √âvaluation du mod√®le...")
        accuracy, precision, recall, f1 = evaluate_model(
            model, X_test, y_test
        )

        result_message = (
            f"‚úÖ R√©sultats de l'√©valuation :\n"
            f"- Accuracy: {accuracy:.4f}\n"
            f"- Precision: {precision:.4f}\n"
            f"- Recall: {recall:.4f}\n"
            f"- F1-score: {f1:.4f}"
        )
        logging.info(result_message)
        print(result_message)

    # Si un mod√®le doit √™tre sauvegard√©
    if model and args.save:
        logging.info(f"üíæ Sauvegarde du mod√®le dans {args.save}...")
        save_model(model, args.save)


if __name__ == "__main__":
    main()
